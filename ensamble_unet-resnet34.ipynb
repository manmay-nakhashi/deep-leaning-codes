{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c19a980f47a900772ebc1b3feed34d0b08385a1c"
   },
   "source": [
    "Unet withh Resnet34 can score 0.81+. \n",
    "Credit goes to these two post and all the kaggler here who give me idea to combine these two cool works.\n",
    "[http://www.kaggle.com/shaojiaxin/u-net-with-simple-resnet-blocks-v2-new-loss\n",
    "](http://)and\n",
    "[http://www.kaggle.com/meaninglesslives/unet-resnet34-in-keras\n",
    "](http://)\n",
    "\n",
    "Big thanks to the author of the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "47b586934d6e5ac3595321450a5567fde8450235"
   },
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import six\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "from keras import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout,BatchNormalization\n",
    "from keras.layers import Conv2D, Concatenate, MaxPooling2D\n",
    "from keras.layers import UpSampling2D, Dropout, BatchNormalization\n",
    "from tqdm import tqdm_notebook\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras.utils import conv_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.engine import InputSpec\n",
    "from keras import backend as K\n",
    "#from keras.applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.regularizers import l2\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "from keras.engine.topology import Input\n",
    "from keras.engine.training import Model\n",
    "from keras.layers.convolutional import Conv2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers.core import Activation, SpatialDropout2D\n",
    "from keras.layers.merge import concatenate,add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "88f4ab2775a014132086744619090f10d3016ab5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet_resnet_version_6.model\n",
      "Unet_resnet_version_6.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t_start = time.time()\n",
    "version = 6\n",
    "basic_name = 'Unet_resnet_version_'+str(version)\n",
    "save_model_name = basic_name + '.model'\n",
    "submission_file = basic_name + '.csv'\n",
    "\n",
    "print(save_model_name)\n",
    "print(submission_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "962c2c6775b5fcf605df8e7c59cbcabe6ba9ceaa"
   },
   "source": [
    "# Params and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "e54e151245d665e42bb95d9cf2e1a33cb9440e48"
   },
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 101\n",
    "\n",
    "epochs = 250\n",
    "batch_size = 32\n",
    "\n",
    "def upsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    #res = np.zeros((img_size_target, img_size_target), dtype=img.dtype)\n",
    "    #res[:img_size_ori, :img_size_ori] = img\n",
    "    #return res\n",
    "    \n",
    "def downsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n",
    "    #return img[:img_size_ori, :img_size_ori]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "530c358f2868a444e8233936996463a66c2cc4f3"
   },
   "source": [
    "# Loading of training/testing ids and depths\n",
    "Reading the training data and the depths, store them in a DataFrame. Also create a test DataFrame with entries from depth not in train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"TGS_salt/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"TGS_salt/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "24d7f3d982bfa582b222f012129acdda55282b6d"
   },
   "source": [
    "# Read images and masks\n",
    "Load the images and masks into the DataFrame and divide the pixel values by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "b18c1f50cefd7504eae7e7b9605be3814c7cad6d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "388641ad03564d79b7c12d77920c524b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manmay_nakhashi/.local/lib/python3.5/site-packages/keras_preprocessing/image.py:489: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df[\"images\"] = [np.array(load_img(\"TGS_salt/train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "86620c6a070571895f4f36ec050a25803915ed74"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a95637b317640c4aa9c60061d092543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manmay_nakhashi/.local/lib/python3.5/site-packages/keras_preprocessing/image.py:489: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df[\"masks\"] = [np.array(load_img(\"TGS_salt/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1137f0a009f10b5f69e4dade5f689e744e9ce1d6"
   },
   "source": [
    "# Calculating the salt coverage and salt coverage classes\n",
    "Counting the number of salt pixels in the masks and dividing them by the image size. Also create 11 coverage classes, -0.1 having no salt at all to 1.0 being salt only.\n",
    "Plotting the distribution of coverages and coverage classes, and the class against the raw coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "18d2aa182a44c65a87c75f41047c653a79bc1c3f"
   },
   "outputs": [],
   "source": [
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "2b13d1ecc7004832e8e042d034922796263054b7"
   },
   "outputs": [],
   "source": [
    "def cov_to_class(val):    \n",
    "    for i in range(0, 11):\n",
    "        if val * 10 <= i :\n",
    "            return i\n",
    "        \n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "00655e32f93f96ebd90dbe94e35ee052f52217cd"
   },
   "source": [
    "# Create train/validation split stratified by salt coverage\n",
    "Using the salt coverage as a stratification criterion. Also show an image to check for correct upsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "2d3c3157512d11e71ac74ce51a937b85bedfe1d1"
   },
   "outputs": [],
   "source": [
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
    "    train_df.index.values,\n",
    "    np.array(train_df.images.map(upsample).tolist()).reshape(-1,img_size_target, img_size_target, 1), \n",
    "    np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    train_df.coverage.values,\n",
    "    train_df.z.values,\n",
    "    test_size = 0.08 , stratify=train_df.coverage_class, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "63ac58ab47921b4e4f54102e2c8b85fa318225f1"
   },
   "source": [
    "# Build U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "3e874f865404ef1e16a1ca907507b2d0ab9b373f"
   },
   "outputs": [],
   "source": [
    "def BatchActivate(x):\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    if activation == True:\n",
    "        x = BatchActivate(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(blockInput, num_filters=16, batch_activate = False):\n",
    "    x = BatchActivate(blockInput)\n",
    "    x = convolution_block(x, num_filters, (3,3) )\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    x = Add()([x, blockInput])\n",
    "    if batch_activate:\n",
    "        x = BatchActivate(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 101, 101, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 101, 101, 16) 160         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 101, 101, 16) 64          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 101, 101, 16) 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 101, 101, 16) 2320        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 101, 101, 16) 64          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 101, 101, 16) 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 101, 101, 16) 2320        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 101, 101, 16) 0           conv2d_39[0][0]                  \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 101, 101, 16) 64          add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 101, 101, 16) 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 101, 101, 16) 2320        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 101, 101, 16) 64          conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 101, 101, 16) 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 101, 101, 16) 2320        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 101, 101, 16) 0           conv2d_41[0][0]                  \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 101, 101, 16) 64          add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 101, 101, 16) 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 50, 50, 16)   0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50, 50, 16)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 50, 50, 32)   4640        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 50, 50, 32)   128         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 50, 50, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 50, 50, 32)   9248        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 50, 50, 32)   128         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 50, 50, 32)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 50, 50, 32)   9248        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 50, 50, 32)   0           conv2d_44[0][0]                  \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 50, 50, 32)   128         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 50, 50, 32)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 50, 50, 32)   9248        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 50, 50, 32)   128         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 50, 50, 32)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 50, 50, 32)   9248        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 50, 50, 32)   0           conv2d_46[0][0]                  \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 50, 50, 32)   128         add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 50, 50, 32)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 25, 25, 32)   0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 25, 25, 32)   0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 25, 25, 64)   18496       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 25, 25, 64)   256         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 25, 25, 64)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 25, 25, 64)   36928       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 25, 25, 64)   256         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 25, 25, 64)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 25, 25, 64)   36928       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 25, 25, 64)   0           conv2d_49[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 25, 25, 64)   256         add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 25, 25, 64)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 25, 25, 64)   36928       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 25, 25, 64)   256         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 25, 25, 64)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 25, 25, 64)   36928       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 25, 25, 64)   0           conv2d_51[0][0]                  \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 25, 25, 64)   256         add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 25, 25, 64)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 12, 12, 64)   0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 12, 12, 64)   0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 128)  73856       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 128)  512         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 128)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 128)  147584      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 128)  512         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 128)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 128)  147584      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 12, 12, 128)  0           conv2d_54[0][0]                  \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 128)  512         add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 128)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 128)  147584      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 128)  512         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 128)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 128)  147584      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 12, 12, 128)  0           conv2d_56[0][0]                  \n",
      "                                                                 add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 128)  512         add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 128)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 6, 6, 128)    0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 6, 6, 128)    0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 6, 6, 256)    295168      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 6, 6, 256)    1024        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 6, 6, 256)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 6, 6, 256)    590080      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 6, 6, 256)    1024        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 6, 6, 256)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 6, 6, 256)    590080      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 6, 6, 256)    0           conv2d_59[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 6, 6, 256)    1024        add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 6, 6, 256)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 6, 6, 256)    590080      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 6, 6, 256)    1024        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 6, 6, 256)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 6, 6, 256)    590080      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 6, 6, 256)    0           conv2d_61[0][0]                  \n",
      "                                                                 add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 6, 6, 256)    1024        add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 6, 6, 256)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 12, 12, 128)  295040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12, 12, 256)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 12, 12, 256)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 128)  295040      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 128)  512         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 128)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 128)  147584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 128)  512         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 128)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 128)  147584      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 12, 12, 128)  0           conv2d_64[0][0]                  \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 128)  512         add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 128)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 128)  147584      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 128)  512         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 128)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 128)  147584      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 12, 12, 128)  0           conv2d_66[0][0]                  \n",
      "                                                                 add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 128)  512         add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 128)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 25, 25, 64)   73792       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 25, 25, 128)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 25, 25, 128)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 25, 25, 64)   73792       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 25, 25, 64)   256         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 25, 25, 64)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 25, 25, 64)   36928       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 25, 25, 64)   256         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 25, 25, 64)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 25, 25, 64)   36928       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 25, 25, 64)   0           conv2d_69[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 25, 25, 64)   256         add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 25, 25, 64)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 25, 25, 64)   36928       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 25, 25, 64)   256         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 25, 25, 64)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 25, 25, 64)   36928       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 25, 25, 64)   0           conv2d_71[0][0]                  \n",
      "                                                                 add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 25, 25, 64)   256         add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 25, 25, 64)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 50, 50, 32)   18464       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 50, 50, 64)   0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 50, 50, 64)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 50, 50, 32)   18464       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 50, 50, 32)   128         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 50, 50, 32)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 50, 50, 32)   9248        activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 50, 50, 32)   128         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 50, 50, 32)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 50, 50, 32)   9248        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 50, 50, 32)   0           conv2d_74[0][0]                  \n",
      "                                                                 conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 50, 50, 32)   128         add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 50, 50, 32)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 50, 50, 32)   9248        activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 50, 50, 32)   128         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 50, 50, 32)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 50, 50, 32)   9248        activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 50, 50, 32)   0           conv2d_76[0][0]                  \n",
      "                                                                 add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 50, 50, 32)   128         add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 50, 50, 32)   0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 101, 101, 16) 4624        activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 101, 101, 32) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 101, 101, 32) 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 101, 101, 16) 4624        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 101, 101, 16) 64          conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 101, 101, 16) 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 101, 101, 16) 2320        activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 101, 101, 16) 64          conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 101, 101, 16) 0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 101, 101, 16) 2320        activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 101, 101, 16) 0           conv2d_79[0][0]                  \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 101, 101, 16) 64          add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 101, 101, 16) 0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 101, 101, 16) 2320        activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 101, 101, 16) 64          conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 101, 101, 16) 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 101, 101, 16) 2320        activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 101, 101, 16) 0           conv2d_81[0][0]                  \n",
      "                                                                 add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 101, 101, 16) 64          add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 101, 101, 16) 0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 101, 101, 1)  17          activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 101, 101, 1)  0           conv2d_82[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,119,857\n",
      "Trainable params: 5,112,497\n",
      "Non-trainable params: 7,360\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = load_model(\"TGS_salt/Unet_resnet_version_3.model\",custom_objects={'my_iou_metric_2': my_iou_metric_2})\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "2b096ffefe1e50535d984522ea4af10f4f5ac012"
   },
   "outputs": [],
   "source": [
    "size = (3, 3)\n",
    "def build_model(model_a, input_layer, start_neurons, DropoutRatio = 0.5):\n",
    "    # 101 -> 50\n",
    "    conv1 = Conv2D(start_neurons * 1, size, activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1, True)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(DropoutRatio/2)(pool1)\n",
    "\n",
    "    # 50 -> 25\n",
    "    conv2 = Conv2D(start_neurons * 2, size, activation=None, padding=\"same\")(pool1)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2, True)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(DropoutRatio)(pool2)\n",
    "\n",
    "    # 25 -> 12\n",
    "    conv3 = Conv2D(start_neurons * 4, size, activation=None, padding=\"same\")(pool2)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4, True)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(DropoutRatio)(pool3)\n",
    "\n",
    "    # 12 -> 6\n",
    "    conv4 = Conv2D(start_neurons * 8, size, activation=None, padding=\"same\")(pool3)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8, True)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(DropoutRatio)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons * 16, size, activation=None, padding=\"same\")(pool4)\n",
    "    convm = residual_block(convm,start_neurons * 16)\n",
    "    convm = residual_block(convm,start_neurons * 16, True)\n",
    "    \n",
    "    # 6 -> 12\n",
    "    activation_53 = model_a.get_layer(\"activation_53\").output\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, size, strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, activation_53])\n",
    "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8, True)\n",
    "    \n",
    "    # 12 -> 25\n",
    "    conv2d_48 = model_a.get_layer(\"conv2d_48\").output\n",
    "    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, size, strides=(2, 2), padding=\"valid\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv2d_48])    \n",
    "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4, True)\n",
    "\n",
    "    # 25 -> 50\n",
    "    activation_43 = model_a.get_layer(\"activation_43\").output\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, size, strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2, activation_43])\n",
    "        \n",
    "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2, True)\n",
    "    \n",
    "    # 50 -> 101\n",
    "    activation_38 = model_a.get_layer(\"activation_38\").output\n",
    "    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, size, strides=(2, 2), padding=\"valid\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, activation_38])\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1, True)\n",
    "    \n",
    "    #uconv1 = Dropout(DropoutRatio/2)(uconv1)\n",
    "    #output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "    output_layer_noActi = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv1)\n",
    "    output_layer =  Activation('sigmoid')(output_layer_noActi)\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "edcb6f536b41d1d9a52c601326a0c11abac24784"
   },
   "source": [
    "# Get Iou Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "1fa9b57c7552aaba173987e21b2c4ef79f095eae"
   },
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B):\n",
    "    batch_size = A.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch]>0, B[batch]>0\n",
    "#         if np.count_nonzero(t) == 0 and np.count_nonzero(p) > 0:\n",
    "#             metric.append(0)\n",
    "#             continue\n",
    "#         if np.count_nonzero(t) >= 1 and np.count_nonzero(p) == 0:\n",
    "#             metric.append(0)\n",
    "#             continue\n",
    "#         if np.count_nonzero(t) == 0 and np.count_nonzero(p) == 0:\n",
    "#             metric.append(1)\n",
    "#             continue\n",
    "        \n",
    "        intersection = np.logical_and(t, p)\n",
    "        union = np.logical_or(t, p)\n",
    "        iou = (np.sum(intersection > 0) + 1e-10 )/ (np.sum(union > 0) + 1e-10)\n",
    "        thresholds = np.arange(0.5, 1, 0.05)\n",
    "        s = []\n",
    "        for thresh in thresholds:\n",
    "            s.append(iou > thresh)\n",
    "        metric.append(np.mean(s))\n",
    "\n",
    "    return np.mean(metric)\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred > 0.47194557444387136], tf.float64)#change 0.5 >> 0.7\n",
    "\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred > 0.5], tf.float64)#change 0.0 >> 0.5\n",
    "\n",
    "def my_iou_metric_3(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred > 0], tf.float64)#change 0.0 >> 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "57220a4517f912e57fd68ddcd3293593550154af"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "61f1b7f07a22a9209ad0c2933c2ddf59f93c9d85"
   },
   "source": [
    "# ResNet 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "bf91b45898924c2e4ca0409cf04abae55bf0e9a9"
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import six\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    Activation,\n",
    "    Dense,\n",
    "    Flatten\n",
    ")\n",
    "from keras.layers.convolutional import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    AveragePooling2D\n",
    ")\n",
    "from keras.layers.merge import add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def _bn_relu(input):\n",
    "    \"\"\"Helper to build a BN -> relu block\n",
    "    \"\"\"\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "\n",
    "def _conv_bn_relu(**conv_params):\n",
    "    \"\"\"Helper to build a conv -> BN -> relu block\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _bn_relu_conv(**conv_params):\n",
    "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
    "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(activation)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _shortcut(input, residual):\n",
    "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
    "    \"\"\"\n",
    "    # Expand channels of shortcut to match residual.\n",
    "    # Stride appropriately to match residual (width, height)\n",
    "    # Should be int if network architecture is correctly configured.\n",
    "    input_shape = K.int_shape(input)\n",
    "    residual_shape = K.int_shape(residual)\n",
    "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
    "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
    "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
    "                          kernel_size=(1, 1),\n",
    "                          strides=(stride_width, stride_height),\n",
    "                          padding=\"valid\",\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2(0.0001))(input)\n",
    "\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "\n",
    "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
    "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "        for i in range(repetitions):\n",
    "            init_strides = (1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                init_strides = (2, 2)\n",
    "            input = block_function(filters=filters, init_strides=init_strides,\n",
    "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
    "        return input\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "                           strides=init_strides,\n",
    "                           padding=\"same\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
    "                                  strides=init_strides)(input)\n",
    "\n",
    "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    Returns:\n",
    "        A final conv layer of filters * 4\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
    "                              strides=init_strides,\n",
    "                              padding=\"same\",\n",
    "                              kernel_initializer=\"he_normal\",\n",
    "                              kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
    "                                     strides=init_strides)(input)\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
    "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _handle_dim_ordering():\n",
    "    global ROW_AXIS\n",
    "    global COL_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        ROW_AXIS = 1\n",
    "        COL_AXIS = 2\n",
    "        CHANNEL_AXIS = 3\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        ROW_AXIS = 2\n",
    "        COL_AXIS = 3\n",
    "\n",
    "\n",
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier\n",
    "\n",
    "\n",
    "class ResnetBuilder(object):\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
    "        \"\"\"Builds a custom ResNet like architecture.\n",
    "        Args:\n",
    "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
    "            num_outputs: The number of outputs at final softmax layer\n",
    "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
    "                The original paper used basic_block for layers < 50\n",
    "            repetitions: Number of repetitions of various block units.\n",
    "                At each block unit, the number of filters are doubled and the input size is halved\n",
    "        Returns:\n",
    "            The keras `Model`.\n",
    "        \"\"\"\n",
    "        _handle_dim_ordering()\n",
    "        if len(input_shape) != 3:\n",
    "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
    "\n",
    "        # Permute dimension order if necessary\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
    "\n",
    "        # Load function from str if needed.\n",
    "        block_fn = _get_block(block_fn)\n",
    "\n",
    "        input = Input(shape=input_shape)\n",
    "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n",
    "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "\n",
    "        block = pool1\n",
    "        filters = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "            filters *= 2\n",
    "\n",
    "        # Last activation\n",
    "        block = _bn_relu(block)\n",
    "\n",
    "        # Classifier block\n",
    "        block_shape = K.int_shape(block)\n",
    "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
    "                                 strides=(1, 1))(block)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\",\n",
    "                      activation=\"softmax\")(flatten1)\n",
    "\n",
    "        model = Model(inputs=input, outputs=dense)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_50(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3b3292a02d84d11d2e27a6261c8de060f7f93ed2"
   },
   "source": [
    "# U-Net with ResNet34 Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "cd5124faf49797d76aa07be02a46fe11c0ec6e21"
   },
   "outputs": [],
   "source": [
    "def UResNet34(input_shape=(128, 128, 1), classes=1, decoder_filters=16, decoder_block_type='upsampling',\n",
    "                       encoder_weights=\"imagenet\", input_tensor=None, activation='sigmoid', **kwargs):\n",
    "\n",
    "    backbone = ResnetBuilder.build_resnet_50(input_shape=input_shape,num_outputs=2)\n",
    "    model_a = load_model(\"TGS_salt/Unet_resnet_version_3.model\",custom_objects={'my_iou_metric_2': my_iou_metric_2})\n",
    "    input_layer = backbone.input #input = backbone.input\n",
    "    output_layer = build_model(model_a ,input_layer, 16,0.5) #x\n",
    "    model = Model(inputs=[input_layer, model_a.input], outputs=output_layer)\n",
    "    adam_optimizer = optimizers.adam(lr = 0.02)\n",
    "    SGD_optimizer=optimizers.SGD(lr=0.005, momentum=0.9)\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=adam_optimizer, metrics=[my_iou_metric_2])\n",
    "    model.name = 'u-resnet34'\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "ce4d8b8704d198a2c384296636e3543f344b7bbe"
   },
   "outputs": [],
   "source": [
    "model1 = UResNet34( input_shape = (1,img_size_target,img_size_target))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cdad5099940be56b00cdfbef38d9efcbd1ff3bb9"
   },
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "88b3f57eac3ec3719b401730dc6d8d2d89d09ccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 101, 101, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 101, 101, 16) 160         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 101, 101, 16) 64          conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, 101, 101, 16) 0           batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 101, 101, 16) 2320        activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 101, 101, 16) 64          conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, 101, 101, 16) 0           batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 101, 101, 16) 2320        activation_320[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_113 (Add)                   (None, 101, 101, 16) 0           conv2d_337[0][0]                 \n",
      "                                                                 conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 101, 101, 16) 64          add_113[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_321 (Activation)     (None, 101, 101, 16) 0           batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 101, 101, 16) 2320        activation_321[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 101, 101, 16) 64          conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, 101, 101, 16) 0           batch_normalization_320[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, 101, 101, 16) 2320        activation_322[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_114 (Add)                   (None, 101, 101, 16) 0           conv2d_339[0][0]                 \n",
      "                                                                 add_113[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, 101, 101, 16) 64          add_114[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, 101, 101, 16) 0           batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 50, 50, 16)   0           activation_323[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 50, 50, 16)   0           max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, 50, 50, 32)   4640        dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 101, 101, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, 50, 50, 32)   128         conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 101, 101, 16) 160         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, 50, 50, 32)   0           batch_normalization_322[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 101, 101, 16) 64          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, 50, 50, 32)   9248        activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 101, 101, 16) 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, 50, 50, 32)   128         conv2d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 101, 101, 16) 2320        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_325 (Activation)     (None, 50, 50, 32)   0           batch_normalization_323[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 101, 101, 16) 64          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, 50, 50, 32)   9248        activation_325[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 101, 101, 16) 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_115 (Add)                   (None, 50, 50, 32)   0           conv2d_342[0][0]                 \n",
      "                                                                 conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 101, 101, 16) 2320        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchN (None, 50, 50, 32)   128         add_115[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 101, 101, 16) 0           conv2d_39[0][0]                  \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_326 (Activation)     (None, 50, 50, 32)   0           batch_normalization_324[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 101, 101, 16) 64          add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, 50, 50, 32)   9248        activation_326[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 101, 101, 16) 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_325 (BatchN (None, 50, 50, 32)   128         conv2d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 101, 101, 16) 2320        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_327 (Activation)     (None, 50, 50, 32)   0           batch_normalization_325[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 101, 101, 16) 64          conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, 50, 50, 32)   9248        activation_327[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 101, 101, 16) 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_116 (Add)                   (None, 50, 50, 32)   0           conv2d_344[0][0]                 \n",
      "                                                                 add_115[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 101, 101, 16) 2320        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_326 (BatchN (None, 50, 50, 32)   128         add_116[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 101, 101, 16) 0           conv2d_41[0][0]                  \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_328 (Activation)     (None, 50, 50, 32)   0           batch_normalization_326[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 101, 101, 16) 64          add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 25, 25, 32)   0           activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 101, 101, 16) 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 25, 25, 32)   0           max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 50, 50, 16)   0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)             (None, 25, 25, 64)   18496       dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50, 50, 16)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_327 (BatchN (None, 25, 25, 64)   256         conv2d_345[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 50, 50, 32)   4640        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_329 (Activation)     (None, 25, 25, 64)   0           batch_normalization_327[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 50, 50, 32)   128         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_346 (Conv2D)             (None, 25, 25, 64)   36928       activation_329[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 50, 50, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_328 (BatchN (None, 25, 25, 64)   256         conv2d_346[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 50, 50, 32)   9248        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_330 (Activation)     (None, 25, 25, 64)   0           batch_normalization_328[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 50, 50, 32)   128         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_347 (Conv2D)             (None, 25, 25, 64)   36928       activation_330[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 50, 50, 32)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_117 (Add)                   (None, 25, 25, 64)   0           conv2d_347[0][0]                 \n",
      "                                                                 conv2d_345[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 50, 50, 32)   9248        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_329 (BatchN (None, 25, 25, 64)   256         add_117[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 50, 50, 32)   0           conv2d_44[0][0]                  \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_331 (Activation)     (None, 25, 25, 64)   0           batch_normalization_329[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 50, 50, 32)   128         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_348 (Conv2D)             (None, 25, 25, 64)   36928       activation_331[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 50, 50, 32)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_330 (BatchN (None, 25, 25, 64)   256         conv2d_348[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 50, 50, 32)   9248        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_332 (Activation)     (None, 25, 25, 64)   0           batch_normalization_330[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 50, 50, 32)   128         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_349 (Conv2D)             (None, 25, 25, 64)   36928       activation_332[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 50, 50, 32)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_118 (Add)                   (None, 25, 25, 64)   0           conv2d_349[0][0]                 \n",
      "                                                                 add_117[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 50, 50, 32)   9248        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_331 (BatchN (None, 25, 25, 64)   256         add_118[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 50, 50, 32)   0           conv2d_46[0][0]                  \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_333 (Activation)     (None, 25, 25, 64)   0           batch_normalization_331[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 50, 50, 32)   128         add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 12, 12, 64)   0           activation_333[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 50, 50, 32)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 12, 12, 64)   0           max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 25, 25, 32)   0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_350 (Conv2D)             (None, 12, 12, 128)  73856       dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 25, 25, 32)   0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_332 (BatchN (None, 12, 12, 128)  512         conv2d_350[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 25, 25, 64)   18496       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_334 (Activation)     (None, 12, 12, 128)  0           batch_normalization_332[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 25, 25, 64)   256         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_351 (Conv2D)             (None, 12, 12, 128)  147584      activation_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 25, 25, 64)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_333 (BatchN (None, 12, 12, 128)  512         conv2d_351[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 25, 25, 64)   36928       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_335 (Activation)     (None, 12, 12, 128)  0           batch_normalization_333[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 25, 25, 64)   256         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_352 (Conv2D)             (None, 12, 12, 128)  147584      activation_335[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 25, 25, 64)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_119 (Add)                   (None, 12, 12, 128)  0           conv2d_352[0][0]                 \n",
      "                                                                 conv2d_350[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 25, 25, 64)   36928       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_334 (BatchN (None, 12, 12, 128)  512         add_119[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 25, 25, 64)   0           conv2d_49[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_336 (Activation)     (None, 12, 12, 128)  0           batch_normalization_334[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 25, 25, 64)   256         add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_353 (Conv2D)             (None, 12, 12, 128)  147584      activation_336[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 25, 25, 64)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_335 (BatchN (None, 12, 12, 128)  512         conv2d_353[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 25, 25, 64)   36928       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_337 (Activation)     (None, 12, 12, 128)  0           batch_normalization_335[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 25, 25, 64)   256         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_354 (Conv2D)             (None, 12, 12, 128)  147584      activation_337[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 25, 25, 64)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_120 (Add)                   (None, 12, 12, 128)  0           conv2d_354[0][0]                 \n",
      "                                                                 add_119[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 25, 25, 64)   36928       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_336 (BatchN (None, 12, 12, 128)  512         add_120[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 25, 25, 64)   0           conv2d_51[0][0]                  \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_338 (Activation)     (None, 12, 12, 128)  0           batch_normalization_336[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 25, 25, 64)   256         add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 6, 6, 128)    0           activation_338[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 25, 25, 64)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 6, 6, 128)    0           max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 12, 12, 64)   0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_355 (Conv2D)             (None, 6, 6, 256)    295168      dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 12, 12, 64)   0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_337 (BatchN (None, 6, 6, 256)    1024        conv2d_355[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 128)  73856       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_339 (Activation)     (None, 6, 6, 256)    0           batch_normalization_337[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 128)  512         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_356 (Conv2D)             (None, 6, 6, 256)    590080      activation_339[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 128)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_338 (BatchN (None, 6, 6, 256)    1024        conv2d_356[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 128)  147584      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_340 (Activation)     (None, 6, 6, 256)    0           batch_normalization_338[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 128)  512         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_357 (Conv2D)             (None, 6, 6, 256)    590080      activation_340[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 128)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_121 (Add)                   (None, 6, 6, 256)    0           conv2d_357[0][0]                 \n",
      "                                                                 conv2d_355[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 128)  147584      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_339 (BatchN (None, 6, 6, 256)    1024        add_121[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 12, 12, 128)  0           conv2d_54[0][0]                  \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_341 (Activation)     (None, 6, 6, 256)    0           batch_normalization_339[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 128)  512         add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_358 (Conv2D)             (None, 6, 6, 256)    590080      activation_341[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 128)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_340 (BatchN (None, 6, 6, 256)    1024        conv2d_358[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 128)  147584      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_342 (Activation)     (None, 6, 6, 256)    0           batch_normalization_340[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 128)  512         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_359 (Conv2D)             (None, 6, 6, 256)    590080      activation_342[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 128)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_122 (Add)                   (None, 6, 6, 256)    0           conv2d_359[0][0]                 \n",
      "                                                                 add_121[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 128)  147584      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_341 (BatchN (None, 6, 6, 256)    1024        add_122[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 12, 12, 128)  0           conv2d_56[0][0]                  \n",
      "                                                                 add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_343 (Activation)     (None, 6, 6, 256)    0           batch_normalization_341[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 128)  512         add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DTran (None, 12, 12, 128)  295040      activation_343[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 128)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 12, 12, 256)  0           conv2d_transpose_11[0][0]        \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 12, 12, 256)  0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_360 (Conv2D)             (None, 12, 12, 128)  295040      dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_342 (BatchN (None, 12, 12, 128)  512         conv2d_360[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, 12, 12, 128)  0           batch_normalization_342[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_361 (Conv2D)             (None, 12, 12, 128)  147584      activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_343 (BatchN (None, 12, 12, 128)  512         conv2d_361[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_345 (Activation)     (None, 12, 12, 128)  0           batch_normalization_343[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_362 (Conv2D)             (None, 12, 12, 128)  147584      activation_345[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_123 (Add)                   (None, 12, 12, 128)  0           conv2d_362[0][0]                 \n",
      "                                                                 conv2d_360[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_344 (BatchN (None, 12, 12, 128)  512         add_123[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, 12, 12, 128)  0           batch_normalization_344[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_363 (Conv2D)             (None, 12, 12, 128)  147584      activation_346[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_345 (BatchN (None, 12, 12, 128)  512         conv2d_363[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, 12, 12, 128)  0           batch_normalization_345[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_364 (Conv2D)             (None, 12, 12, 128)  147584      activation_347[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_124 (Add)                   (None, 12, 12, 128)  0           conv2d_364[0][0]                 \n",
      "                                                                 add_123[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_346 (BatchN (None, 12, 12, 128)  512         add_124[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, 12, 12, 128)  0           batch_normalization_346[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DTran (None, 25, 25, 64)   73792       activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 25, 25, 128)  0           conv2d_transpose_12[0][0]        \n",
      "                                                                 conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 25, 25, 128)  0           concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_365 (Conv2D)             (None, 25, 25, 64)   73792       dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_347 (BatchN (None, 25, 25, 64)   256         conv2d_365[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_349 (Activation)     (None, 25, 25, 64)   0           batch_normalization_347[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_366 (Conv2D)             (None, 25, 25, 64)   36928       activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_348 (BatchN (None, 25, 25, 64)   256         conv2d_366[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_350 (Activation)     (None, 25, 25, 64)   0           batch_normalization_348[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_367 (Conv2D)             (None, 25, 25, 64)   36928       activation_350[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_125 (Add)                   (None, 25, 25, 64)   0           conv2d_367[0][0]                 \n",
      "                                                                 conv2d_365[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_349 (BatchN (None, 25, 25, 64)   256         add_125[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_351 (Activation)     (None, 25, 25, 64)   0           batch_normalization_349[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_368 (Conv2D)             (None, 25, 25, 64)   36928       activation_351[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_350 (BatchN (None, 25, 25, 64)   256         conv2d_368[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_352 (Activation)     (None, 25, 25, 64)   0           batch_normalization_350[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_369 (Conv2D)             (None, 25, 25, 64)   36928       activation_352[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_126 (Add)                   (None, 25, 25, 64)   0           conv2d_369[0][0]                 \n",
      "                                                                 add_125[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_351 (BatchN (None, 25, 25, 64)   256         add_126[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_353 (Activation)     (None, 25, 25, 64)   0           batch_normalization_351[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DTran (None, 50, 50, 32)   18464       activation_353[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 50, 50, 64)   0           conv2d_transpose_13[0][0]        \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 50, 50, 64)   0           concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_370 (Conv2D)             (None, 50, 50, 32)   18464       dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_352 (BatchN (None, 50, 50, 32)   128         conv2d_370[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_354 (Activation)     (None, 50, 50, 32)   0           batch_normalization_352[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_371 (Conv2D)             (None, 50, 50, 32)   9248        activation_354[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_353 (BatchN (None, 50, 50, 32)   128         conv2d_371[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_355 (Activation)     (None, 50, 50, 32)   0           batch_normalization_353[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_372 (Conv2D)             (None, 50, 50, 32)   9248        activation_355[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_127 (Add)                   (None, 50, 50, 32)   0           conv2d_372[0][0]                 \n",
      "                                                                 conv2d_370[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_354 (BatchN (None, 50, 50, 32)   128         add_127[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_356 (Activation)     (None, 50, 50, 32)   0           batch_normalization_354[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_373 (Conv2D)             (None, 50, 50, 32)   9248        activation_356[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_355 (BatchN (None, 50, 50, 32)   128         conv2d_373[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_357 (Activation)     (None, 50, 50, 32)   0           batch_normalization_355[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_374 (Conv2D)             (None, 50, 50, 32)   9248        activation_357[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_128 (Add)                   (None, 50, 50, 32)   0           conv2d_374[0][0]                 \n",
      "                                                                 add_127[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_356 (BatchN (None, 50, 50, 32)   128         add_128[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_358 (Activation)     (None, 50, 50, 32)   0           batch_normalization_356[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DTran (None, 101, 101, 16) 4624        activation_358[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 101, 101, 32) 0           conv2d_transpose_14[0][0]        \n",
      "                                                                 activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 101, 101, 32) 0           concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_375 (Conv2D)             (None, 101, 101, 16) 4624        dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_357 (BatchN (None, 101, 101, 16) 64          conv2d_375[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_359 (Activation)     (None, 101, 101, 16) 0           batch_normalization_357[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_376 (Conv2D)             (None, 101, 101, 16) 2320        activation_359[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_358 (BatchN (None, 101, 101, 16) 64          conv2d_376[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_360 (Activation)     (None, 101, 101, 16) 0           batch_normalization_358[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_377 (Conv2D)             (None, 101, 101, 16) 2320        activation_360[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_129 (Add)                   (None, 101, 101, 16) 0           conv2d_377[0][0]                 \n",
      "                                                                 conv2d_375[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_359 (BatchN (None, 101, 101, 16) 64          add_129[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_361 (Activation)     (None, 101, 101, 16) 0           batch_normalization_359[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_378 (Conv2D)             (None, 101, 101, 16) 2320        activation_361[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_360 (BatchN (None, 101, 101, 16) 64          conv2d_378[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_362 (Activation)     (None, 101, 101, 16) 0           batch_normalization_360[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_379 (Conv2D)             (None, 101, 101, 16) 2320        activation_362[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_130 (Add)                   (None, 101, 101, 16) 0           conv2d_379[0][0]                 \n",
      "                                                                 add_129[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_361 (BatchN (None, 101, 101, 16) 64          add_130[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_363 (Activation)     (None, 101, 101, 16) 0           batch_normalization_361[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_380 (Conv2D)             (None, 101, 101, 1)  17          activation_363[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_364 (Activation)     (None, 101, 101, 1)  0           conv2d_380[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 6,006,129\n",
      "Trainable params: 5,996,369\n",
      "Non-trainable params: 9,760\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7360, 101, 101, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.summary()\n",
    "x_train2 = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "y_train2 = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n",
    "x_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "03a93a946d7449614b18d32aa77fd39b297e0667"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 101, 101, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.5,\n",
    "                                   zoom_range = 0.5,\n",
    "                                   horizontal_flip = True,\n",
    "                                   vertical_flip = True,\n",
    "                                   rotation_range = True)\n",
    "\n",
    "training_set = train_datagen.flow(x_train, y_train,\n",
    "                                 batch_size = 32)\n",
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class SGDRScheduler(Callback):\n",
    "\n",
    "    '''Cosine annealing learning rate scheduler with periodic restarts.\n",
    "\n",
    "\n",
    "\n",
    "    # Usage\n",
    "\n",
    "        ```python\n",
    "\n",
    "            schedule = SGDRScheduler(min_lr=1e-5,\n",
    "\n",
    "                                     max_lr=1e-2,\n",
    "\n",
    "                                     steps_per_epoch=np.ceil(epoch_size/batch_size),\n",
    "\n",
    "                                     lr_decay=0.9,\n",
    "\n",
    "                                     cycle_length=5,\n",
    "\n",
    "                                     mult_factor=1.5)\n",
    "\n",
    "            model.fit(X_train, Y_train, epochs=100, callbacks=[schedule])\n",
    "\n",
    "        ```\n",
    "\n",
    "\n",
    "\n",
    "    # Arguments\n",
    "\n",
    "        min_lr: The lower bound of the learning rate range for the experiment.\n",
    "\n",
    "        max_lr: The upper bound of the learning rate range for the experiment.\n",
    "\n",
    "        steps_per_epoch: Number of mini-batches in the dataset. Calculated as `np.ceil(epoch_size/batch_size)`. \n",
    "\n",
    "        lr_decay: Reduce the max_lr after the completion of each cycle.\n",
    "\n",
    "                  Ex. To reduce the max_lr by 20% after each cycle, set this value to 0.8.\n",
    "\n",
    "        cycle_length: Initial number of epochs in a cycle.\n",
    "\n",
    "        mult_factor: Scale epochs_to_restart after each full cycle completion.\n",
    "\n",
    "\n",
    "\n",
    "    # References\n",
    "\n",
    "        Blog post: jeremyjordan.me/nn-learning-rate\n",
    "\n",
    "        Original paper: http://arxiv.org/abs/1608.03983\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "\n",
    "                 min_lr,\n",
    "\n",
    "                 max_lr,\n",
    "\n",
    "                 steps_per_epoch,\n",
    "\n",
    "                 lr_decay=1,\n",
    "\n",
    "                 cycle_length=10,\n",
    "\n",
    "                 mult_factor=2):\n",
    "\n",
    "\n",
    "\n",
    "        self.min_lr = min_lr\n",
    "\n",
    "        self.max_lr = max_lr\n",
    "\n",
    "        self.lr_decay = lr_decay\n",
    "\n",
    "\n",
    "\n",
    "        self.batch_since_restart = 0\n",
    "\n",
    "        self.next_restart = cycle_length\n",
    "\n",
    "\n",
    "\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "\n",
    "\n",
    "\n",
    "        self.cycle_length = cycle_length\n",
    "\n",
    "        self.mult_factor = mult_factor\n",
    "\n",
    "\n",
    "\n",
    "        self.history = {}\n",
    "\n",
    "\n",
    "\n",
    "    def clr(self):\n",
    "\n",
    "        '''Calculate the learning rate.'''\n",
    "\n",
    "        fraction_to_restart = self.batch_since_restart / (self.steps_per_epoch * self.cycle_length)\n",
    "\n",
    "        lr = self.min_lr + 0.5 * (self.max_lr - self.min_lr) * (1 + np.cos(fraction_to_restart * np.pi))\n",
    "\n",
    "        return lr\n",
    "\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "\n",
    "        '''Initialize the learning rate to the minimum value at the start of training.'''\n",
    "\n",
    "        logs = logs or {}\n",
    "\n",
    "        K.set_value(self.model.optimizer.lr, self.max_lr)\n",
    "\n",
    "\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "\n",
    "        '''Record previous batch statistics and update the learning rate.'''\n",
    "\n",
    "        logs = logs or {}\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "\n",
    "        for k, v in logs.items():\n",
    "\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "\n",
    "\n",
    "\n",
    "        self.batch_since_restart += 1\n",
    "\n",
    "        K.set_value(self.model.optimizer.lr, self.clr())\n",
    "\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        '''Check for end of current cycle, apply restarts when necessary.'''\n",
    "\n",
    "        if epoch + 1 == self.next_restart:\n",
    "\n",
    "            self.batch_since_restart = 0\n",
    "\n",
    "            self.cycle_length = np.ceil(self.cycle_length * self.mult_factor)\n",
    "\n",
    "            self.next_restart += self.cycle_length\n",
    "\n",
    "            self.max_lr *= self.lr_decay\n",
    "\n",
    "            self.best_weights = self.model.get_weights()\n",
    "\n",
    "\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "\n",
    "        '''Set weights to the values from the end of the most recent cycle for best performance.'''\n",
    "\n",
    "        self.model.set_weights(self.best_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prev = load_model(\"TGS_salt/Unet_resnet_version_3.model\",custom_objects={'my_iou_metric_2': my_iou_metric_2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f5a6b1abaa4681cba3b608bc5f33cf260370d82a"
   },
   "source": [
    "# Training 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6059176b6c4bf2bcf0c10624ce8889df19241892",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7360 samples, validate on 320 samples\n",
      "Epoch 1/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.1433 - my_iou_metric_2: 0.7031 - val_loss: 0.6052 - val_my_iou_metric_2: 0.4428\n",
      "\n",
      "Epoch 00001: my_iou_metric_2 improved from -inf to 0.70307, saving model to Unet_resnet_version_6.model\n",
      "Epoch 2/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.1315 - my_iou_metric_2: 0.7155 - val_loss: 0.1370 - val_my_iou_metric_2: 0.7284\n",
      "\n",
      "Epoch 00002: my_iou_metric_2 improved from 0.70307 to 0.71554, saving model to Unet_resnet_version_6.model\n",
      "Epoch 3/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.1272 - my_iou_metric_2: 0.7169 - val_loss: 0.2515 - val_my_iou_metric_2: 0.6334\n",
      "\n",
      "Epoch 00003: my_iou_metric_2 improved from 0.71554 to 0.71689, saving model to Unet_resnet_version_6.model\n",
      "Epoch 4/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.1242 - my_iou_metric_2: 0.7236 - val_loss: 0.1449 - val_my_iou_metric_2: 0.7278\n",
      "\n",
      "Epoch 00004: my_iou_metric_2 improved from 0.71689 to 0.72357, saving model to Unet_resnet_version_6.model\n",
      "Epoch 5/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.1210 - my_iou_metric_2: 0.7376 - val_loss: 0.2461 - val_my_iou_metric_2: 0.7350\n",
      "\n",
      "Epoch 00005: my_iou_metric_2 improved from 0.72357 to 0.73761, saving model to Unet_resnet_version_6.model\n",
      "Epoch 6/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.1160 - my_iou_metric_2: 0.7342 - val_loss: 0.1868 - val_my_iou_metric_2: 0.7056\n",
      "\n",
      "Epoch 00006: my_iou_metric_2 did not improve from 0.73761\n",
      "Epoch 7/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.1138 - my_iou_metric_2: 0.7424 - val_loss: 0.1708 - val_my_iou_metric_2: 0.7244\n",
      "\n",
      "Epoch 00007: my_iou_metric_2 improved from 0.73761 to 0.74238, saving model to Unet_resnet_version_6.model\n",
      "Epoch 8/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.1069 - my_iou_metric_2: 0.7441 - val_loss: 0.1439 - val_my_iou_metric_2: 0.7434\n",
      "\n",
      "Epoch 00008: my_iou_metric_2 improved from 0.74238 to 0.74409, saving model to Unet_resnet_version_6.model\n",
      "Epoch 9/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.1062 - my_iou_metric_2: 0.7514 - val_loss: 0.2192 - val_my_iou_metric_2: 0.7491\n",
      "\n",
      "Epoch 00009: my_iou_metric_2 improved from 0.74409 to 0.75137, saving model to Unet_resnet_version_6.model\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.009999999776482582.\n",
      "Epoch 10/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0875 - my_iou_metric_2: 0.7682 - val_loss: 0.1215 - val_my_iou_metric_2: 0.7750\n",
      "\n",
      "Epoch 00010: my_iou_metric_2 improved from 0.75137 to 0.76821, saving model to Unet_resnet_version_6.model\n",
      "Epoch 11/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0847 - my_iou_metric_2: 0.7749 - val_loss: 0.1363 - val_my_iou_metric_2: 0.7869\n",
      "\n",
      "Epoch 00011: my_iou_metric_2 improved from 0.76821 to 0.77493, saving model to Unet_resnet_version_6.model\n",
      "Epoch 12/250\n",
      "7360/7360 [==============================] - 147s 20ms/step - loss: 0.0840 - my_iou_metric_2: 0.7727 - val_loss: 0.1073 - val_my_iou_metric_2: 0.7972\n",
      "\n",
      "Epoch 00012: my_iou_metric_2 did not improve from 0.77493\n",
      "Epoch 13/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0794 - my_iou_metric_2: 0.7759 - val_loss: 0.1537 - val_my_iou_metric_2: 0.7691\n",
      "\n",
      "Epoch 00013: my_iou_metric_2 improved from 0.77493 to 0.77592, saving model to Unet_resnet_version_6.model\n",
      "Epoch 14/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0795 - my_iou_metric_2: 0.7793 - val_loss: 0.1307 - val_my_iou_metric_2: 0.8059\n",
      "\n",
      "Epoch 00014: my_iou_metric_2 improved from 0.77592 to 0.77927, saving model to Unet_resnet_version_6.model\n",
      "Epoch 15/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0746 - my_iou_metric_2: 0.7871 - val_loss: 0.1749 - val_my_iou_metric_2: 0.7666\n",
      "\n",
      "Epoch 00015: my_iou_metric_2 improved from 0.77927 to 0.78713, saving model to Unet_resnet_version_6.model\n",
      "Epoch 16/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0724 - my_iou_metric_2: 0.7853 - val_loss: 0.1566 - val_my_iou_metric_2: 0.7744\n",
      "\n",
      "Epoch 00016: my_iou_metric_2 did not improve from 0.78713\n",
      "Epoch 17/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0734 - my_iou_metric_2: 0.7882 - val_loss: 0.1213 - val_my_iou_metric_2: 0.7653\n",
      "\n",
      "Epoch 00017: my_iou_metric_2 improved from 0.78713 to 0.78817, saving model to Unet_resnet_version_6.model\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 18/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0653 - my_iou_metric_2: 0.7964 - val_loss: 0.0964 - val_my_iou_metric_2: 0.8150\n",
      "\n",
      "Epoch 00018: my_iou_metric_2 improved from 0.78817 to 0.79636, saving model to Unet_resnet_version_6.model\n",
      "Epoch 19/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0583 - my_iou_metric_2: 0.8049 - val_loss: 0.1139 - val_my_iou_metric_2: 0.8072\n",
      "\n",
      "Epoch 00019: my_iou_metric_2 improved from 0.79636 to 0.80492, saving model to Unet_resnet_version_6.model\n",
      "Epoch 20/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0607 - my_iou_metric_2: 0.8021 - val_loss: 0.1117 - val_my_iou_metric_2: 0.8044\n",
      "\n",
      "Epoch 00020: my_iou_metric_2 did not improve from 0.80492\n",
      "Epoch 21/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0579 - my_iou_metric_2: 0.8068 - val_loss: 0.1385 - val_my_iou_metric_2: 0.8044\n",
      "\n",
      "Epoch 00021: my_iou_metric_2 improved from 0.80492 to 0.80683, saving model to Unet_resnet_version_6.model\n",
      "Epoch 22/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0586 - my_iou_metric_2: 0.8093 - val_loss: 0.1182 - val_my_iou_metric_2: 0.7953\n",
      "\n",
      "Epoch 00022: my_iou_metric_2 improved from 0.80683 to 0.80931, saving model to Unet_resnet_version_6.model\n",
      "Epoch 23/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0580 - my_iou_metric_2: 0.8131 - val_loss: 0.1005 - val_my_iou_metric_2: 0.8247\n",
      "\n",
      "Epoch 00023: my_iou_metric_2 improved from 0.80931 to 0.81312, saving model to Unet_resnet_version_6.model\n",
      "Epoch 24/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0582 - my_iou_metric_2: 0.8066 - val_loss: 0.1130 - val_my_iou_metric_2: 0.8175\n",
      "\n",
      "Epoch 00024: my_iou_metric_2 did not improve from 0.81312\n",
      "Epoch 25/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0606 - my_iou_metric_2: 0.8055 - val_loss: 0.1206 - val_my_iou_metric_2: 0.8162\n",
      "\n",
      "Epoch 00025: my_iou_metric_2 did not improve from 0.81312\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 26/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0524 - my_iou_metric_2: 0.8146 - val_loss: 0.1320 - val_my_iou_metric_2: 0.8066\n",
      "\n",
      "Epoch 00026: my_iou_metric_2 improved from 0.81312 to 0.81465, saving model to Unet_resnet_version_6.model\n",
      "Epoch 27/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0521 - my_iou_metric_2: 0.8174 - val_loss: 0.1178 - val_my_iou_metric_2: 0.8150\n",
      "\n",
      "Epoch 00027: my_iou_metric_2 improved from 0.81465 to 0.81739, saving model to Unet_resnet_version_6.model\n",
      "Epoch 28/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0509 - my_iou_metric_2: 0.8182 - val_loss: 0.1411 - val_my_iou_metric_2: 0.8200\n",
      "\n",
      "Epoch 00028: my_iou_metric_2 improved from 0.81739 to 0.81819, saving model to Unet_resnet_version_6.model\n",
      "Epoch 29/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0512 - my_iou_metric_2: 0.8185 - val_loss: 0.1483 - val_my_iou_metric_2: 0.8141\n",
      "\n",
      "Epoch 00029: my_iou_metric_2 improved from 0.81819 to 0.81855, saving model to Unet_resnet_version_6.model\n",
      "Epoch 30/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0505 - my_iou_metric_2: 0.8176 - val_loss: 0.1238 - val_my_iou_metric_2: 0.8066\n",
      "\n",
      "Epoch 00030: my_iou_metric_2 did not improve from 0.81855\n",
      "Epoch 31/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0508 - my_iou_metric_2: 0.8175 - val_loss: 0.1234 - val_my_iou_metric_2: 0.8094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00031: my_iou_metric_2 did not improve from 0.81855\n",
      "Epoch 32/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0489 - my_iou_metric_2: 0.8206 - val_loss: 0.1495 - val_my_iou_metric_2: 0.8063\n",
      "\n",
      "Epoch 00032: my_iou_metric_2 improved from 0.81855 to 0.82056, saving model to Unet_resnet_version_6.model\n",
      "Epoch 33/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0487 - my_iou_metric_2: 0.8216 - val_loss: 0.1259 - val_my_iou_metric_2: 0.8122\n",
      "\n",
      "Epoch 00033: my_iou_metric_2 improved from 0.82056 to 0.82158, saving model to Unet_resnet_version_6.model\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 34/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0471 - my_iou_metric_2: 0.8267 - val_loss: 0.1216 - val_my_iou_metric_2: 0.8162\n",
      "\n",
      "Epoch 00034: my_iou_metric_2 improved from 0.82158 to 0.82670, saving model to Unet_resnet_version_6.model\n",
      "Epoch 35/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0475 - my_iou_metric_2: 0.8252 - val_loss: 0.1232 - val_my_iou_metric_2: 0.8134\n",
      "\n",
      "Epoch 00035: my_iou_metric_2 did not improve from 0.82670\n",
      "Epoch 36/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0477 - my_iou_metric_2: 0.8279 - val_loss: 0.1205 - val_my_iou_metric_2: 0.8175\n",
      "\n",
      "Epoch 00036: my_iou_metric_2 improved from 0.82670 to 0.82788, saving model to Unet_resnet_version_6.model\n",
      "Epoch 37/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0455 - my_iou_metric_2: 0.8259 - val_loss: 0.1349 - val_my_iou_metric_2: 0.8141\n",
      "\n",
      "Epoch 00037: my_iou_metric_2 did not improve from 0.82788\n",
      "Epoch 38/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0462 - my_iou_metric_2: 0.8260 - val_loss: 0.1370 - val_my_iou_metric_2: 0.8222\n",
      "\n",
      "Epoch 00038: my_iou_metric_2 did not improve from 0.82788\n",
      "Epoch 39/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0453 - my_iou_metric_2: 0.8313 - val_loss: 0.1271 - val_my_iou_metric_2: 0.8206\n",
      "\n",
      "Epoch 00039: my_iou_metric_2 improved from 0.82788 to 0.83130, saving model to Unet_resnet_version_6.model\n",
      "Epoch 40/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0464 - my_iou_metric_2: 0.8270 - val_loss: 0.1188 - val_my_iou_metric_2: 0.8247\n",
      "\n",
      "Epoch 00040: my_iou_metric_2 did not improve from 0.83130\n",
      "Epoch 41/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0456 - my_iou_metric_2: 0.8291 - val_loss: 0.1361 - val_my_iou_metric_2: 0.8153\n",
      "\n",
      "Epoch 00041: my_iou_metric_2 did not improve from 0.83130\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 42/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0449 - my_iou_metric_2: 0.8306 - val_loss: 0.1288 - val_my_iou_metric_2: 0.8187\n",
      "\n",
      "Epoch 00042: my_iou_metric_2 did not improve from 0.83130\n",
      "Epoch 43/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0450 - my_iou_metric_2: 0.8277 - val_loss: 0.1224 - val_my_iou_metric_2: 0.8194\n",
      "\n",
      "Epoch 00043: my_iou_metric_2 did not improve from 0.83130\n",
      "Epoch 44/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0436 - my_iou_metric_2: 0.8275 - val_loss: 0.1294 - val_my_iou_metric_2: 0.8197\n",
      "\n",
      "Epoch 00044: my_iou_metric_2 did not improve from 0.83130\n",
      "Epoch 45/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0440 - my_iou_metric_2: 0.8288 - val_loss: 0.1331 - val_my_iou_metric_2: 0.8206\n",
      "\n",
      "Epoch 00045: my_iou_metric_2 did not improve from 0.83130\n",
      "Epoch 46/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0451 - my_iou_metric_2: 0.8286 - val_loss: 0.1343 - val_my_iou_metric_2: 0.8137\n",
      "\n",
      "Epoch 00046: my_iou_metric_2 did not improve from 0.83130\n",
      "Epoch 47/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0439 - my_iou_metric_2: 0.8290 - val_loss: 0.1351 - val_my_iou_metric_2: 0.8153\n",
      "\n",
      "Epoch 00047: my_iou_metric_2 did not improve from 0.83130\n",
      "Epoch 48/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0442 - my_iou_metric_2: 0.8288 - val_loss: 0.1365 - val_my_iou_metric_2: 0.8181\n",
      "\n",
      "Epoch 00048: my_iou_metric_2 did not improve from 0.83130\n",
      "Epoch 49/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0437 - my_iou_metric_2: 0.8337 - val_loss: 0.1296 - val_my_iou_metric_2: 0.8169\n",
      "\n",
      "Epoch 00049: my_iou_metric_2 improved from 0.83130 to 0.83374, saving model to Unet_resnet_version_6.model\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Epoch 50/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0435 - my_iou_metric_2: 0.8304 - val_loss: 0.1345 - val_my_iou_metric_2: 0.8200\n",
      "\n",
      "Epoch 00050: my_iou_metric_2 did not improve from 0.83374\n",
      "Epoch 51/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0428 - my_iou_metric_2: 0.8322 - val_loss: 0.1301 - val_my_iou_metric_2: 0.8162\n",
      "\n",
      "Epoch 00051: my_iou_metric_2 did not improve from 0.83374\n",
      "Epoch 52/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0432 - my_iou_metric_2: 0.8344 - val_loss: 0.1299 - val_my_iou_metric_2: 0.8225\n",
      "\n",
      "Epoch 00052: my_iou_metric_2 improved from 0.83374 to 0.83440, saving model to Unet_resnet_version_6.model\n",
      "Epoch 53/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0424 - my_iou_metric_2: 0.8355 - val_loss: 0.1304 - val_my_iou_metric_2: 0.8253\n",
      "\n",
      "Epoch 00053: my_iou_metric_2 improved from 0.83440 to 0.83554, saving model to Unet_resnet_version_6.model\n",
      "Epoch 54/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0430 - my_iou_metric_2: 0.8303 - val_loss: 0.1325 - val_my_iou_metric_2: 0.8231\n",
      "\n",
      "Epoch 00054: my_iou_metric_2 did not improve from 0.83554\n",
      "Epoch 55/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0428 - my_iou_metric_2: 0.8340 - val_loss: 0.1382 - val_my_iou_metric_2: 0.8194\n",
      "\n",
      "Epoch 00055: my_iou_metric_2 did not improve from 0.83554\n",
      "Epoch 56/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0432 - my_iou_metric_2: 0.8309 - val_loss: 0.1322 - val_my_iou_metric_2: 0.8222\n",
      "\n",
      "Epoch 00056: my_iou_metric_2 did not improve from 0.83554\n",
      "Epoch 57/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0427 - my_iou_metric_2: 0.8306 - val_loss: 0.1347 - val_my_iou_metric_2: 0.8216\n",
      "\n",
      "Epoch 00057: my_iou_metric_2 did not improve from 0.83554\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Epoch 58/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0434 - my_iou_metric_2: 0.8325 - val_loss: 0.1330 - val_my_iou_metric_2: 0.8200\n",
      "\n",
      "Epoch 00058: my_iou_metric_2 did not improve from 0.83554\n",
      "Epoch 59/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0426 - my_iou_metric_2: 0.8316 - val_loss: 0.1325 - val_my_iou_metric_2: 0.8222\n",
      "\n",
      "Epoch 00059: my_iou_metric_2 did not improve from 0.83554\n",
      "Epoch 60/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0430 - my_iou_metric_2: 0.8335 - val_loss: 0.1332 - val_my_iou_metric_2: 0.8187\n",
      "\n",
      "Epoch 00060: my_iou_metric_2 did not improve from 0.83554\n",
      "Epoch 61/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0418 - my_iou_metric_2: 0.8362 - val_loss: 0.1331 - val_my_iou_metric_2: 0.8191\n",
      "\n",
      "Epoch 00061: my_iou_metric_2 improved from 0.83554 to 0.83617, saving model to Unet_resnet_version_6.model\n",
      "Epoch 62/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0433 - my_iou_metric_2: 0.8313 - val_loss: 0.1297 - val_my_iou_metric_2: 0.8222\n",
      "\n",
      "Epoch 00062: my_iou_metric_2 did not improve from 0.83617\n",
      "Epoch 63/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0424 - my_iou_metric_2: 0.8341 - val_loss: 0.1312 - val_my_iou_metric_2: 0.8194\n",
      "\n",
      "Epoch 00063: my_iou_metric_2 did not improve from 0.83617\n",
      "Epoch 64/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0425 - my_iou_metric_2: 0.8324 - val_loss: 0.1304 - val_my_iou_metric_2: 0.8206\n",
      "\n",
      "Epoch 00064: my_iou_metric_2 did not improve from 0.83617\n",
      "Epoch 65/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0419 - my_iou_metric_2: 0.8351 - val_loss: 0.1287 - val_my_iou_metric_2: 0.8222\n",
      "\n",
      "Epoch 00065: my_iou_metric_2 did not improve from 0.83617\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 66/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0426 - my_iou_metric_2: 0.8331 - val_loss: 0.1299 - val_my_iou_metric_2: 0.8203\n",
      "\n",
      "Epoch 00066: my_iou_metric_2 did not improve from 0.83617\n",
      "Epoch 67/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0425 - my_iou_metric_2: 0.8354 - val_loss: 0.1306 - val_my_iou_metric_2: 0.8197\n",
      "\n",
      "Epoch 00067: my_iou_metric_2 did not improve from 0.83617\n",
      "Epoch 68/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0417 - my_iou_metric_2: 0.8333 - val_loss: 0.1303 - val_my_iou_metric_2: 0.8241\n",
      "\n",
      "Epoch 00068: my_iou_metric_2 did not improve from 0.83617\n",
      "Epoch 69/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0426 - my_iou_metric_2: 0.8331 - val_loss: 0.1308 - val_my_iou_metric_2: 0.8234\n",
      "\n",
      "Epoch 00069: my_iou_metric_2 did not improve from 0.83617\n",
      "Epoch 70/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0427 - my_iou_metric_2: 0.8374 - val_loss: 0.1301 - val_my_iou_metric_2: 0.8206\n",
      "\n",
      "Epoch 00070: my_iou_metric_2 improved from 0.83617 to 0.83739, saving model to Unet_resnet_version_6.model\n",
      "Epoch 71/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0418 - my_iou_metric_2: 0.8322 - val_loss: 0.1293 - val_my_iou_metric_2: 0.8247\n",
      "\n",
      "Epoch 00071: my_iou_metric_2 did not improve from 0.83739\n",
      "Epoch 72/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0421 - my_iou_metric_2: 0.8344 - val_loss: 0.1301 - val_my_iou_metric_2: 0.8244\n",
      "\n",
      "Epoch 00072: my_iou_metric_2 did not improve from 0.83739\n",
      "Epoch 73/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0415 - my_iou_metric_2: 0.8314 - val_loss: 0.1287 - val_my_iou_metric_2: 0.8244\n",
      "\n",
      "Epoch 00073: my_iou_metric_2 did not improve from 0.83739\n",
      "Epoch 74/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0423 - my_iou_metric_2: 0.8326 - val_loss: 0.1310 - val_my_iou_metric_2: 0.8259\n",
      "\n",
      "Epoch 00074: my_iou_metric_2 did not improve from 0.83739\n",
      "Epoch 75/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0420 - my_iou_metric_2: 0.8352 - val_loss: 0.1297 - val_my_iou_metric_2: 0.8241\n",
      "\n",
      "Epoch 00075: my_iou_metric_2 did not improve from 0.83739\n",
      "Epoch 76/250\n",
      "7360/7360 [==============================] - 141s 19ms/step - loss: 0.0417 - my_iou_metric_2: 0.8337 - val_loss: 0.1312 - val_my_iou_metric_2: 0.8206\n",
      "\n",
      "Epoch 00076: my_iou_metric_2 did not improve from 0.83739\n",
      "Epoch 77/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0417 - my_iou_metric_2: 0.8300 - val_loss: 0.1305 - val_my_iou_metric_2: 0.8206\n",
      "\n",
      "Epoch 00077: my_iou_metric_2 did not improve from 0.83739\n",
      "Epoch 78/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0422 - my_iou_metric_2: 0.8331 - val_loss: 0.1333 - val_my_iou_metric_2: 0.8231\n",
      "\n",
      "Epoch 00078: my_iou_metric_2 did not improve from 0.83739\n",
      "Epoch 79/250\n",
      "7360/7360 [==============================] - 140s 19ms/step - loss: 0.0428 - my_iou_metric_2: 0.8346 - val_loss: 0.1314 - val_my_iou_metric_2: 0.8241\n",
      "\n",
      "Epoch 00079: my_iou_metric_2 did not improve from 0.83739\n",
      "Epoch 80/250\n",
      "5536/7360 [=====================>........] - ETA: 34s - loss: 0.0411 - my_iou_metric_2: 0.8364"
     ]
    }
   ],
   "source": [
    "# #early_stopping = EarlyStopping(patience=10, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='my_iou_metric_2', mode = 'max',patience = 16, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='my_iou_metric_2', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='my_iou_metric_2', mode = 'auto',factor=0.5, patience=8, min_lr=0.0001, verbose=1)\n",
    "schedule = SGDRScheduler(min_lr=0.0001,\n",
    "                         max_lr=0.01,\n",
    "                         steps_per_epoch= 32,\n",
    "                         lr_decay=0.9,\n",
    "                         cycle_length=3,\n",
    "                         mult_factor=1.5)\n",
    "\n",
    "history = model1.fit([x_train2, x_train2], y_train2,\n",
    "                    validation_data=[[x_valid, x_valid], y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[ early_stopping, model_checkpoint,reduce_lr], \n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bb27d5a56aeb6a570f133a0cdc20a35db2276b24"
   },
   "source": [
    "#early_stopping = EarlyStopping(monitor='my_iou_metric', mode = 'max',patience=10, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='my_iou_metric', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='my_iou_metric', mode = 'max',factor=0.5, patience=5, min_lr=0.0001, verbose=1)\n",
    "\n",
    "history = model1.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[ model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3361604e650be76cb78960679caaa7fcff0e42fa"
   },
   "outputs": [],
   "source": [
    "# model1 = load_model(\"TGS_salt/Unet_resnet_version_3.model\",custom_objects={'my_iou_metric_2': my_iou_metric_2})\n",
    "# # remove layter activation layer and use losvasz loss\n",
    "# input_x = model1.layers[0].input\n",
    "\n",
    "# output_layer = model1.layers[-5].input\n",
    "# model = Model(input_x, output_layer)\n",
    "# Adam = optimizers.adam(lr = 0.02)\n",
    "# SGD_optimizer=optimizers.SGD(lr=0.005, momentum=0.9)\n",
    "# # lovasz_loss need input range (-∞，+∞), so cancel the last \"sigmoid\" activation  \n",
    "# # Then the default threshod for pixel prediction is 0 instead of 0.5, as in my_iou_metric_2.\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=Adam, metrics=[my_iou_metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e2ff03c3269d44c25bae086d07bad46162479f05"
   },
   "outputs": [],
   "source": [
    "# early_stopping = EarlyStopping(monitor='my_iou_metric', mode = 'max',patience=16, verbose=1)\n",
    "# model_checkpoint = ModelCheckpoint(save_model_name,monitor='my_iou_metric', \n",
    "#                                    mode = 'max', save_best_only=True, verbose=1)\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='my_iou_metric', mode = 'max',factor=0.5, patience=8, min_lr=0.0001, verbose=1)\n",
    "# #epochs = 50\n",
    "# #batch_size = 32\n",
    "# schedule = SGDRScheduler(min_lr=0.0001,\n",
    "#                          max_lr=0.01,\n",
    "#                          steps_per_epoch= 32,\n",
    "#                          lr_decay=0.9,\n",
    "#                          cycle_length=6,\n",
    "#                          mult_factor=1.5)\n",
    "# history = model.fit(x_train2, y_train2,\n",
    "#                     validation_data=[x_valid, y_valid], \n",
    "#                     epochs=epochs,\n",
    "#                     batch_size=batch_size,\n",
    "#                     callbacks=[model_checkpoint,reduce_lr,early_stopping, schedule], \n",
    "#                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "8b5629d083ea2657e2633aa5f992ab3c3a94e695"
   },
   "outputs": [],
   "source": [
    "# model = load_model(save_model_name,custom_objects={'my_iou_metric': my_iou_metric,\n",
    "#                                                   'lovasz_loss': lovasz_loss})\n",
    "model = load_model(save_model_name,custom_objects={'my_iou_metric_2': my_iou_metric_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "a85e0e9aa27a8583f14c94cbfed1f05986a6db50"
   },
   "outputs": [],
   "source": [
    "def predict_result(model,x_test,img_size_target): # predict both orginal and reflect x\n",
    "    x_test_reflect =  np.array([np.fliplr(x) for x in x_test])\n",
    "    preds_test = model.predict(x_test).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test2_refect = model.predict(x_test_reflect).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test += np.array([ np.fliplr(x) for x in preds_test2_refect] )\n",
    "    return preds_test/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "457c019b1299cda500be688f1650d19d6e295c7d"
   },
   "outputs": [],
   "source": [
    "preds_valid = predict_result(model,x_valid,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "0db29e372452971b1803c630eaa4d8028472be01"
   },
   "outputs": [],
   "source": [
    "#Score the model and do a threshold optimization by the best IoU.\n",
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "\n",
    "\n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    #  if all zeros, original code  generate wrong  bins [-0.5 0 0.5],\n",
    "    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n",
    "#     temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))\n",
    "    #print(temp1)\n",
    "    intersection = temp1[0]\n",
    "    #print(\"temp2 = \",temp1[1])\n",
    "    #print(intersection.shape)\n",
    "   # print(intersection)\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    #print(np.histogram(labels, bins = true_objects))\n",
    "    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n",
    "    #print(\"area_true = \",area_true)\n",
    "    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "  \n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    intersection[intersection == 0] = 1e-9\n",
    "    \n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "98855c45d8581fd3905868212097b67289abbeef"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf5f75c6a794178bc1be61522d7de69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.8475    0.8515625 0.8521875 0.8515625 0.85125   0.850625  0.8509375\n",
      " 0.8509375 0.851875  0.851875  0.851875  0.8509375 0.85      0.8509375\n",
      " 0.850625  0.8503125 0.8496875 0.8496875 0.850625  0.850625  0.8503125\n",
      " 0.849375  0.8496875 0.8496875 0.84875   0.8496875 0.8503125 0.8496875\n",
      " 0.8496875 0.84875   0.8465625]\n"
     ]
    }
   ],
   "source": [
    "## Scoring for last model, choose threshold by validation data \n",
    "thresholds_ori = np.linspace(0.3, 0.7, 31)\n",
    "# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\n",
    "thresholds = np.log(thresholds_ori/(1-thresholds_ori)) \n",
    "\n",
    "# ious = np.array([get_iou_vector(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "# print(ious)\n",
    "ious = np.array([iou_metric_batch(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "print(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "732df3d18fdcbc0cf9b4a29277dab54edaf2fb69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa975af21d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# instead of using default 0 as threshold, use validation data to find the best threshold.\n",
    "threshold_best_index = np.argmax(ious) \n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "\n",
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "9d2dc3af209c88cccf01f5942c7c7cb7169d93f9"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "used for converting the decoded image to rle mask\n",
    "Fast compared to previous one\n",
    "\"\"\"\n",
    "def rle_encode(im):\n",
    "    '''\n",
    "    im: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = im.flatten(order = 'F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "9ae1d1987c155d93c23f7a74ab496c55cc9e5d68"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7889dc8089b4953b216e4f692736010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manmay_nakhashi/.local/lib/python3.5/site-packages/keras_preprocessing/image.py:489: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array([(np.array(load_img(\"TGS_salt/test/images/{}.png\".format(idx), grayscale = True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "358db4425710e7eb38617b533e521d074aa3dfdc"
   },
   "outputs": [],
   "source": [
    "preds_test = predict_result(model,x_test,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "14e17a1f08fd9dee16fd72e0ce3420cfc102d7db"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de26067b66ad4a44adbdb590f3f06eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "pred_dict = {idx: rle_encode(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\n",
    "t2 = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "b0571c5a0da9a5ed97b587a322dbdc65c393699a"
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv(submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "4045f793f4c11a0feb3e22201076ccd15c0ac6d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel run time = 4.523008776240879hours\n"
     ]
    }
   ],
   "source": [
    "t_finish = time.time()\n",
    "print(\"Kernel run time = \" + str((t_finish-t_start)/3600) + \"hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bd6ce9b4d5fc80a2502a43e80299d628fb5ffc42"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c6628f65171ebdacc2144cfcebdaf376567536c5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f7f2a2c77bd1f77fd4a02e428e91b57eff005f0a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ed67d37f1713502684514ae3d4c41fb7fc5ed240"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
